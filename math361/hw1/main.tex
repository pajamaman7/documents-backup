\documentclass{article}
\input{preamble.tex}
\pagestyle{fancy}
\lhead{Assignment \#$1$}
\rhead{Name: Thomas Boyko; UCID: 30191728}
\chead{}

\begin{document}
\begin{enumerate} 
    \item Let $V$ and $W$ be finite dimensional vector spaces with given bases $\mathcal{B} = \{\vec{b}_1,\ldots,\vec{b}_n\}$ and $\mathcal{D} = \{\vec{d}_1,\ldots,\vec{d}_m\}$, respectively.
      \begin{enumerate}
        \item For a given $\vec{x} \in V$, there are unique scalars so that $\vec{x} = a_1\vec{b}_1 + \cdots + a_n\vec{b}_n$. Define the vector $[\vec{x}]_{\mathcal{B}} := (a_1,\ldots,a_n)^T \in \mathbb{C}^n$. Show that the map $\vec{x} \mapsto [\vec{x}]_{\mathcal{B}}$ is a linear isomorphism from $V$ into $\mathbb{C}^n$.

          \paragraph{Linearity: }Let $\vec{x},\vec{y}\in V$. Then write $\vec{x} = a_1\vec{b}_1 + \cdots + a_n\vec{b}_n$ and $\vec{y} = c_1\vec{b}_1 + \cdots + c_n\vec{b}_n$. Now:
          \[
              [\vec{x}+\vec{y}]_{\mathcal{B}}=\begin{bmatrix} a_1+c_1\\\vdots\\ a_n+c_n \end{bmatrix} 
            =\begin{bmatrix} a_1\\\vdots\\ a_n \end{bmatrix} 
            +\begin{bmatrix} c_1\\\vdots\\ c_n \end{bmatrix} 
            =[\vec{x}   ]_{\mathcal{B}}
            +[\vec{y}   ]_{\mathcal{B}}
          \] 
           \[
               [\alpha\vec{x}]_\mathcal{B}=\begin{bmatrix} \alpha a_1\\\vdots \\ \alpha a_n \end{bmatrix} 
               =\alpha \begin{bmatrix} a_1\\\vdots\\ a_n \end{bmatrix} 
               =\alpha[\vec{x}]_{\mathcal{B}}
          .\] 
          So $[\cdot ]_{\mathcal{B}}$ is linear. 

          \paragraph{Isomorphism: } Since $\dim V=\dim \mathbb{C}^{n}=n$, it will suffice to show that this mapping is injective. We do so by showing  $\ker [\cdot ]_\mathcal{B}=\{0\} $. Clearly $0$ is in the kernel since $[0]_{\mathcal{B}}=[0\vec{x}]_\mathcal{B}=0[\vec{x}]_\mathcal{B}=0$. For inclusion the other way, let $\vec{x}\in \ker [\cdot ]_\mathcal{B} $. Then $[\vec{x}]_\mathcal{B}=0$; meaning the basis representation of $\vec{x}$ is through zero coefficients; and
          \[
          \vec{x}=0\vec{b}_1+\ldots+0\vec{b}_n=0
          .\] 
          So $\ker[\cdot ]_\mathcal{B}=\{0\} $, and this map is injective. But since the spaces are of the same dimension it must also be surjective. So the map is a linear isomorphism from $V$ to $\mathbb{C}^{n}$. 
        \item Let $T : V \to W$ be a linear map. In class, we defined the matrix representation of $T$ with respect to $\mathcal{B}$ and $\mathcal{D}$ as the $m \times n$ matrix $[T]_{\mathcal{B}\mathcal{D}} = [[T\vec{b}_1]_{\mathcal{D}},\ldots,[T\vec{b}_n]_{\mathcal{D}}].$ In other words, the $j$-the column of $[T]_{\mathcal{B}\mathcal{D}}$ is $[T\vec{b}_j]_{\mathcal{D}}.$ Show that $[T]_{\mathcal{B}\mathcal{D}}[\vec{x}]_{\mathcal{B}}=[T\vec{x}]_{\mathcal{D}}$ for any $\vec{x} \in V$.
            \paragraph{Solution: }Let $T:V\to W$ be linear, then write $\vec{x}=a_1\vec{b}_1+\ldots+a_n\vec{b_n}$.
            \begin{align*}
                [T]_{\mathcal{B}\mathcal{D}}[\vec{x}]_{\mathcal{B}}
                &= \left[ [T\vec{b}_1]_\mathcal{D}\ldots[T\vec{b}_n ]_\mathcal{D} \right]
                \begin{bmatrix} a_1\\ \vdots \\ a_n \end{bmatrix} \\
                &= a_1[T\vec{b}_1]_\mathcal{D}+\ldots+ a_n[T\vec{b}_n ]_\mathcal{D}  \\
                &= [a_1 T\vec{b}_1 +\ldots+ a_n T\vec{b}_n ]_\mathcal{D}  &\text{By linearity of }[\cdot ]_{\mathcal{D}}\\
                &= \left[T(a_1 \vec{b}_1 +\ldots+ a_n \vec{b}_n) \right]_\mathcal{D}  &\text{By linearity of }T\\
                &=[T\vec{x}]_{\mathcal{D}}
            .\end{align*}
      \item Show that $[T]_{\mathcal{B}\mathcal{D}}$ is a linear isomorphism from $L(V,W)$ (the vector space of linear maps from $V$ to $W$) to $M_{mn}(\mathbb{C})$ (vector space of $m \times n$ complex matrices).
          \paragraph{Linearity: }Let $T,S$ be linear from $V$ to $W$. Then:
          \begin{align*}
              [T+S]_{\mathcal{B}\mathcal{D}}&= \left[ [(T+S)\vec{b}_1]_\mathcal{D} \ldots [(T+S)\vec{b}_n]_\mathcal{D}  \right] \\
               &= \left[ [(T\vec{b}_1+S\vec{b}_1)]_\mathcal{D} \ldots [(T\vec{b}_n+S\vec{b}_n)]_\mathcal{D}  \right]\\
               &= \left[ [T\vec{b}_1]_\mathcal{D}\ldots [T\vec{b}_n]_\mathcal{D} \right] + \left[ [S\vec{b}_1]_\mathcal{D}\ldots [S\vec{b}_n]_\mathcal{D} \right] &\text{By Linearity of }[\cdot]_\mathcal{D}\\
               &=  [S]_{\mathcal{B}\mathcal{D}} +[T]_{\mathcal{B}\mathcal{D}} 
          .\end{align*}
          And then letting $\alpha\in \mathbb{C}$,
           \begin{align*}
               \alpha[T]_{\mathcal{B}\mathcal{D}}&=\alpha\left[ [T\vec{b}_1]_\mathcal{D}\ldots[T\vec{b}_n]_\mathcal{D} \right] \\
                         &=\left[ \alpha[T\vec{b}_1]_\mathcal{D} \ldots\alpha[T\vec{b}_n]_\mathcal{D}  \right]&\text{Linearity of }[\cdot]_\mathcal{D}\\
                         &=\left[ [\alpha T\vec{b}_1]_\mathcal{D} \ldots[\alpha T\vec{b}_n]_\mathcal{D} \right] \\
               &= [\alpha T]_{\mathcal{B}\mathcal{D}} 
          .\end{align*}
          \paragraph{Injective: } %TODO Better to find an inverse or do kernel zero? Instinct says inverse sending the basis representation to its linear combination. Ker not that bad but the dimension argument is weird. Math exchange says that it's necessary to find the isomorphism in order to prove the same dimension anyways
          
          Clearly  $0\in \ker[\cdot ]_{\mathcal{BD}}$; take any transformation $T$ and $[0]_{\mathcal{BD}}=[T-T]_{\mathcal{BD}}=[T]_{\mathcal{BD}}-[T]_{\mathcal{BD}}=0$ .

      Ten let $\mathcal{B}=\{b_1,\ldots ,b_n\} $ and $T\in \ker [\cdot ]_\mathcal{BD} $. Then:
      \begin{align*}
          [T]_{\mathcal{BD}}&=0\\
          \left[ [Tb_1]_\mathcal{D}\ldots [Tb_n]_\mathcal{D}\right] &=[0\ldots 0]
      .\end{align*} 
      Then $[Tb_i]_{\mathcal{D}}=0$ for any basis vector $b_i$. In particular this means that $TB_i=0$, since $[\cdot ]_\mathcal{D}$ is an isomorphism. Now for any arbitrary $v\in V,$ write $v=a_1b_1+\ldots a_nb_n$. Then $Tv=T(a_1b_1+\ldots a_n b_n)=a_1Tb_1+\ldots+a_nTb_n=0+\ldots+0=0$ and $T=0$.

      Therefore $\ker[\cdot ]_{\mathcal{BD}}=\{0\} $.
      \paragraph{Surjective:} The argument that $\dim L(V,W)=\dim M_{mn}(\mathbb{C})$ proves difficult, so instead we show directly that $[L(V,W)]_{BD}=M_{mn}(\mathbb{C})$
      \end{enumerate}
    \item Let $V$, $W$ and $U$ be finite dimensional vector spaces with given bases: 

        $\mathcal{B} = \{\vec{b}_1,\ldots,\vec{b}_n\}, \mathcal{D} = \{\vec{d}_1,\ldots,\vec{d}_m\}, \text{ and } \mathcal{F} = \{f_1,\ldots,f_k\}$, respectively. Suppose $T : V \to W$ and $S : W \to U$ are linear. Prove or disprove the following statement for the composition linear map  $ST : V \to U$:
      \[
      [ST]_{\mathcal{B}\mathcal{F}}=[S]_{\mathcal{DF}}[T]_{\mathcal{B}\mathcal{D}}
      .\] 

      \paragraph{Solution: }%TODO is this way good????
      We make great use of the property shown in 1(b). Where it is used will be marked with $(*)$. Let $v\in V$ be arbitrary and recall that $[v]_{\mathcal{B}}$ is unique since $[\cdot ]_\mathcal{B}$ is an isomorphism. 
      \begin{align*}
          [ST]_{\mathcal{B}\mathcal{F}}[v]_\mathcal{B}&= [STv]_\mathcal{F}&(*) \\
                                              &= [S]_{\mathcal{D}\mathcal{F}}[Tv]_{\mathcal{D}}&(*) \\
                                              &= [S]_{\mathcal{D}\mathcal{F}}[T]_{\mathcal{B}\mathcal{D}}[v]_\mathcal{B}&(*) 
      \end{align*}
      So we have shown that these matrices $[ST]_{\mathcal{B}\mathcal{F}}$ and  $[S]_{\mathcal{DF}}[T]_{\mathcal{B}\mathcal{D}} $ agree upon all vectors in the image of $[\cdot ]_\mathcal{B}$. However since this particular mapping is onto, we know this to be all of  $\mathbb{C}^{n}$. This means the matrices agree upon all of $\mathbb{C}^{n}$ and therefore they must be equal. 
  \item Let $V$ be a finite dimensional vector space and $T : V \to V$ be linear. Show that $\sigma(T)=\sigma([T]_{\mathcal{B}})$ where $\mathcal{B}$ is any basis for $V$.
    \paragraph{Solution:} $\subseteq $: Let $ \lambda\in \sigma(T)$, and let $\vec{v}$ be an associated eigenvector. We show that $[\vec{v}]_\mathcal{B}$ is an eigenvector for $\lambda$ under $[T]_\mathcal{B}$.
    \begin{align*}
        [T]_\mathcal{B}[\vec{v}]_\mathcal{B}&= [T\vec{v}]_\mathcal{B}&\text{By 1(b)} \\
                                            &= [\lambda \vec{v}]_\mathcal{B} \\
                                            &= \lambda[ \vec{v}]_\mathcal{B} &[\cdot ]_\mathcal{B}\text{ is linear }
    .\end{align*}

    $\supseteq$: Let $\tau$ be an eigenvalue of $[T]_B$ with associated eigenvector  $\vec{y}$. Since  $[\cdot ]_\mathcal{B}$ is an isomorphism, $\vec{y}$ has a unique preimage under the mapping, say $\vec{x}$ so that $[\vec{x}]_\mathcal{B}=\vec{y}$. Recall that $[\cdot ]_\mathcal{B}$ also must have an inverse. Denote this $[\cdot ]^{-1}_\mathcal{B}$. %TODO who says this inverse is necessarily linear?
    \begin{align*}
        T\vec{x}&=[[T\vec{x} ]_\mathcal{B}]^{-1}_\mathcal{B}\\
                &= [[T]_\mathcal{B}[\vec{x}]_\mathcal{B}]_\mathcal{B}^{-1}&\text{Again by 1(b)} \\
                &=  [[T]_\mathcal{B}\vec{y}]_\mathcal{B}^{-1}\\
                &= [\tau\vec{y}]_\mathcal{B}^{-1} \\
                &= \tau[\vec{y}]_\mathcal{B}^{-1} &[\cdot ]_\mathcal{B} \text{ is linear }\\
                &= \tau\vec{x} 
    .\end{align*}
    Therefore $\sigma(T)=\sigma([T]_\mathcal{B})$.
\item Let $A$ be an $n \times n$ complex matrix with $\sigma(A) = \{1\}$. Show that $A$ is diagonalizable if and only if $A$ is the identity matrix.
    \paragraph{$\implies$}: Let $A$ be a diagonalizable matrix and $\sigma(A)=\{1\} $. Then there exists some invertible $S$ so that $S^{-1}AS=D=\text{diag}\{1,\ldots,1\}=I$. Multiply both sides:
    \begin{align*}
        S^{-1}AS&= I \\
        SS^{-1}ASS^{-1}&=SIS^{-1}\\
        A&=SS^{-1}\\
        A&= I
    .\end{align*}

    \paragraph{$\impliedby$:} Conversely, if $A=I$, then take the invertible matrix $I$, so that $IAI^{-1}=A=I$, and since $I$ is diagonal, $A$ is diagonalizable. 

\item Determine whether or not the derivative map $D : P_n \rightarrow P_n$ given by $Dp(z) = p'(z)$ is diagonalizable.
    \paragraph{Claim: }The derivative map defined above is nilpotent; the $k+1$-th derivative of a polynomial of degree $k\in C[x]$ is identically zero. 
    \begin{proof} [Proof of claim:]
        
  Proceed by induction on the degree of $p$. 
  \paragraph{Base case:} If $p$ has degree $0$, then $p$ is constant and has zero derivative, and as such, any subsequent derivative will be zero.
  \paragraph{Inductive hypothesis:} Suppose that the $k$-th derivative of any  $p \in \mathbb{C}[x]$ with 

  $\deg p=k-1$ is identically zero.
  \paragraph{Inductive step:} Let $f(x)\in \mathbb{C}[x]$ be of degree $k$. Write $f(x)=a_0+a_1x+\ldots+a_kx^{k}$ for complex $a_i$ . Then $Df(x)=a_1+2a_2+\ldots+ka_nx^{k-1}$. And since this polynomial $Df$ is of degree $k-1$, by the inductive hypothesis the $k$-th derivative of this must be zero, and \newline $D^{k+1}f=D(D^{k}f)=0$. Therefore by induction on $\deg f$, the derivative operator is nilpotent on $\mathbb{C}[x]$
    \end{proof}
  \paragraph{Solution: } The derivative map is nilpotent on $\mathbb{C}[x]$, and since nilpotent operators are not diagonalizable, the derivative operator is not diagonalizable

\end{enumerate}
\end{document}
